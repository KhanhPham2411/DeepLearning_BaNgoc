{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hack 3.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KhanhPham2411/DeepLearning_BaNgoc_Protonx/blob/master/Hackathon/03/Hack_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLE33nJlAksi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "08e91d59-8472-4f03-dab5-f31b08a29f66"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/protonx-cloud-storage/data.txt\n",
        "data = open('data.txt').read()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-14 14:52:30--  https://storage.googleapis.com/protonx-cloud-storage/data.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.125.128, 74.125.23.128, 74.125.203.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.125.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 93578 (91K) [text/plain]\n",
            "Saving to: ‘data.txt.3’\n",
            "\n",
            "\rdata.txt.3            0%[                    ]       0  --.-KB/s               \rdata.txt.3          100%[===================>]  91.38K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2020-08-14 14:52:30 (124 MB/s) - ‘data.txt.3’ saved [93578/93578]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEFCYjEydgyn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3QHseGbAoXg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = data.lower().split(\"\\n\")"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1A8CKAgUvFjn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOo6vZjLDPpe",
        "colab_type": "text"
      },
      "source": [
        "## Yêu cầu: Sinh từ tiếp khi gõ bất cứ một câu nào có chiều dài bất kỳ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKsfQdUaAwEA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dự đoán 10 từ tiếp theo\n",
        "# despite of wrinkles -> this thy golden time to heart's sight ' must '"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "US982AN3DhzI",
        "colab_type": "text"
      },
      "source": [
        "### 1. Xử lý dữ liệu. Chia features, label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PBrJTe4Dnsb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTB0DE1YiqOm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a6b4a4f5-b3fc-4024-837b-623de01e2169"
      },
      "source": [
        "total_words"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3211"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S1wMIUqgPgp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_sequences.append(n_gram_sequence)\n",
        "\n",
        "# pad sequences \n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# create predictors and label\n",
        "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zscBhCtDkwK",
        "colab_type": "text"
      },
      "source": [
        "### 2. Xây dựng model\n",
        "#### Yêu cầu độ chính xác: 80%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPnVzu6Vcgbo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, LSTM, Bidirectional, Dropout"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18r5pRWfEqup",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "0a20f04f-23b5-402e-a85d-1f05368918bb"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(150, return_sequences=True)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "adam = Adam(lr=0.00025)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_10 (Embedding)     (None, 10, 100)           321100    \n",
            "_________________________________________________________________\n",
            "bidirectional_10 (Bidirectio (None, 10, 300)           301200    \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 10, 300)           0         \n",
            "_________________________________________________________________\n",
            "lstm_18 (LSTM)               (None, 150)               270600    \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 512)               77312     \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 3211)              1647243   \n",
            "=================================================================\n",
            "Total params: 2,617,455\n",
            "Trainable params: 2,617,455\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-44CVMoj3Uc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adam = Adam(lr=0.00025)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['acc'])\n"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aa2Gn8nhtnt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DESIRED_ACCURACY = 0.8\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if(logs.get('acc')>DESIRED_ACCURACY):\n",
        "            print(\"\\nReached 80% accuracy so cancelling training!\")\n",
        "            self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bNWIxutDmd-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "7e6852c9-154e-4357-8edf-2fb785f69463"
      },
      "source": [
        "history = model.fit(xs, ys, epochs=1000, shuffle=True, verbose=1, callbacks=[callbacks])"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "483/484 [============================>.] - ETA: 0s - loss: 0.6922 - acc: 0.8078\n",
            "Reached 80% accuracy so cancelling training!\n",
            "484/484 [==============================] - 12s 24ms/step - loss: 0.6923 - acc: 0.8078\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8heXdtslDpGU",
        "colab_type": "text"
      },
      "source": [
        "### 3. Dự đoán 10 từ tiếp theo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnFicgjcDuqu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e379ae60-b08a-4fbd-d5d6-064f9e513d81"
      },
      "source": [
        "test_seq = 'despite of wrinkles'\n",
        "# sinh ra 10 từ tiếp theo sau test_seq\n",
        "# despite of wrinkles this thy golden time to heart's sight ' must '\n",
        "next_words = 10\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([test_seq])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = model.predict_classes(token_list, verbose=0)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\ttest_seq += \" \" + output_word\n",
        "print(test_seq)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "despite of wrinkles this thy golden time spread fired blind lie exceeds '\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}